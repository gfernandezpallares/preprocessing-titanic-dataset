---
title: "Preprocessing Titanic Dataset"
author: "Guillem Fernández Pallarès i Miquel Tomé Carreño"
date: "`r format(Sys.Date(),'%e de %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
header-includes: \DeclareUnicodeCharacter{0007}{}
toc-title: Índex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Packages to import
library("tidyr")
library("party")
library("rpart")
library("rpart.plot")
library("corrplot")
library("pROC")
library("nortest")
```

#1. Descripció del dataset

El dataset escollit ha estat *Titanic: Machine Learning from Disaster* disponible [a aquest enllaç](https://www.kaggle.com/c/titanic/data). Amb aquest joc de dades es pretenen aplicar algorismes de Machine Learning posteriors al preprocessat de les dades per crear models predictius que permetin construir un model que prevegui, en funció d'unes variables determinades, un determinat passatger sobreviurà o no al conegut accident.

El dataset descarregat es composa de 3 fitxers, els quals es troben en format `csv`.

El primer fitxer, `gender_submission.csv`, és un exemple del fitxer resultant a presentar un cop realitzat l'exercici, i conté una relació dels passatgers que van sobreviure amb dues columnes: identificador del passatger i el sexe (0 = Dona i 1 = Home). 

Els altres dos fitxers contenen el conjunt de dades que ens serviran per entrenar l'algorisme (conjunt `train.csv`) i les dades de test (conjunt `test.csv`) que ens serviran per calcular el nivell de precisió en les prediccions del nostre algorisme i que seran les dades que haurem d'entregar per tal que se'ns valori en la competició de Kaggle.

Les variables que podem trobar tant al fitxer train.csv com al de test.csv, són les següents:

- **survival**: Variable dicotòmica que expressa si el passatger va sobreviure (valor 1) o no (valor 0).
- **pclass**: Variable que expressa la categoria en la que viatjava el passatger (primera, segona o tercera).
- **sex**: Ens indica si el passatger era un home (valor 1) o una dona (valor 0).
- **age**: Edat del passatger en anys.
- **sibsp**: El número de germans que hi tenia al vaixell o si hi havia el seu espòs o muller. En cas que aquesta variable sigui 1, no tindrem capacitat per esbrinar si es tracta d'un germà o de la parella.
- **parch**: Semblant a la variable anterior, expressa quants fills més hi havia al vaixell o, en cas de ser un infant, quants pares l'acompanyaven.
- **ticket**: El número de bitllet que tenia el passatger. Equivaldria a un Id del bitllet.
- **fare**: El cost del bitllet que havia pagat el passatger.
- **cabin**: El número de cabina on s'allotjava el passatger. Equivaldria a un Id de la cabina.
- **embarked**: El port on va embarcar el passatger. En aquest cas hi tenim 3 possibilitats (C = Cherbourg, Q = Queenstown i S = Southampton).

En una primera inspecció, veiem que el conjunt d'entrenament consta de 891 registres, mentre que el de test en té 418. Per saber com funciona la divisió de les dades entre els conjunts train i test és bo mirar [aquest vídeo](https://materials.campus.uoc.edu/cdocent/PID_00251986/).

#2. Integració i selecció de dades

Les dades utilitzades es troben dividides en dos datasets diferents: un d'ells conté el subconjunt de dades que serà utilitzat al set d'entrenament o *training set* i l'altre conté aquelles que seran utilitzades al test de prova o *testing set* per comprovar l'eficàcia del model construït. Els dos subconjunts s'integraran en un de sol per facilitar el recompte de valors perduts que presenten.

Primerament, es llegiran ambdós fitxers i s'afegirà una columna a cadascun d'ells que indicarà si un determinat registre pertany al subconjunt d'entrenament o de prova. Addicionalment, cal esmentar que al subset de prova s'ha afegit la columna `Survived` amb valors perduts `NA`, que és la variable dicotòmica a predir i que està present a l'altre subset.

Pel que fa a la selecció de les dades, es trindran en compte la totalitat de registres dels quals es disposa, els quals seran considerats durant la fase de preprocessat de les dades. No obstant, es descartaran les variables categòriques que es considera que no aporten cap tipus d'informació a l'anàlisi: `Name`, `Ticket` i `Cabin`.

```{r read files}
# Lectura del training set.
r_train <- read.csv("train.csv")
head(r_train)

# Lectura del testing set i addició de la variable a predir.
r_test <- read.csv("test.csv")
r_test$Survived <- NA
head(r_test)

# Addició de la columna amb la classificació train-test.
r_train$train_test <- "train"
r_test$train_test <- "test"

# Eliminació de les columnes que no són d'interès.
r_train[,c("Name","Ticket","Cabin")] <- NULL
r_test[,c("Name","Ticket","Cabin")] <- NULL

# Concatenació dels dos subsets.
data <- rbind(r_train,
              r_test)

# Comprovació que s'ha concatenat correctament.
nrow(r_train) + nrow(r_test) == nrow(data)
```

# 3. Neteja de les dades

El següent pas a dur a terme abans de l'anàlisi de les dades, és la neteja i preprocessat d'aquestes. En els dos següents apartats es realitzarà un breu estudi per determinar si existeixen valors perduts i/o valors extrems.

## 3.1. Valors perduts

Primerament, s'inspeccionaran les dades de les quals es disposa amb la finalitat de trobar els valors perduts. Es consideraran tant els que tenen associat el valor `NA` com els que tenen camps en blanc. Addicionalment, es comprovarà que els `NA` introduïts manualment a la variable `Survived` en apartats anteriors es corresponen a la totalitat de valors perduts de la columna, és a dir, es comprovarà que la variable que es vol predir no contingui valors perduts al subset d'entrenament de l'algorisme.

```{r missing values}
# Total de valors perduts al dataset.
for (i in 1:ncol(data)-1) {
  cat("\nLa columna",
      colnames(data[i]),
      "presenta",
      sum(is.na(data[,i]) | data[,i] == ""),
      "valors nuls o buits.")
}

# Comprovació que les dades d'entrenament no tenen valors perduts a Survived.
cat("\n\nLa suma de valors perduts per al conjunt de dades són:",sum(is.na(data$Survived[data$train_test == "train"])))
```

Com es pot observar, les columnes que contenen valors perduts són `Survived` (tot i que es corresponen amb els assignats manualment), `Age`, `Fare` i `Embarked`. Es tractaran diferentment en funció del seu format.

\begin{enumerate}
  \item Els valors perduts de la variable `Survived` es deixaran sense tractar, ja que corresponen als que han estat inserits manualment a la columna per tal de poder ajuntar el subset d'entrenament i el de prova. Posteriorment, es descartarà aquesta variable quan es torni a separar els dos subconjunts de dades.
  \item A les variables `Age` i `Fare`, ambdues numèriques, es substituiran els valors perduts per la mediana de la variable. Es tria aquesta opció perquè la mediana és una mesura de tendència central menys sensible a valors extrems que la mitjana.
  \item La columna `Embarked`, corresponent al port on va embarcar el passatger en qüestió, conté una variable categòrica que no pot ser ordenada en ordre creixent o decreixent, com podria fer-se amb una variable numèrica. Per tant, en aquest cas s'associarà als valors perduts d'aquesta columna el valor més freqüent.
\end{enumerate}

Es crearà una funció per tal de facilitar el preprocessat de les dades que pertanyen als dos subconjunts, el d'entrenament i el de prova.

```{r treat missing values v2}
clean_transform <- function(x){
  
  # Neteja i transformació de la variable Sex.
  x$Sex_Numeric <- as.character(x$Sex)
  x$Sex_Numeric[x$Sex_Numeric=="male"] <- "0"
  x$Sex_Numeric[x$Sex_Numeric=="female"] <- "1"
  x$Sex_Numeric <- as.integer(x$Sex_Numeric)
  
  # Passem la variable Age a Integer i als valors buits els associem la mediana.
  # Els valors entre 0 i 1 es converteixen tots a 1.
  x$Age <- as.integer(x$Age)
  x$Age[is.na(x$Age) | x$Age == ""] <- median(x$Age, na.rm = TRUE)
  x$Age[x$Age==0] <- 1
  
  # Els valors buits o NA de Fare es substitueixen per la mediana.
  x$Fare[is.na(x$Fare) |
               x$Fare == ""] <- median(x$Fare, na.rm = TRUE)
  
  # Els valors buits o NA de Embarked els hi associem el valor més freqüent.
  x$Embarked[is.na(x$Embarked) |
               x$Embarked == ""] <- names(which.max(table(r_train$Embarked,
                                                          useNA="no")))
  
  # Convertim la variable Embarked a numèrica
  x$Embarked_Numeric <- as.character(x$Embarked)
  x$Embarked_Numeric[x$Embarked_Numeric=="C"] <- "1"
  x$Embarked_Numeric[x$Embarked_Numeric=="Q"] <- "2"
  x$Embarked_Numeric[x$Embarked_Numeric=="S"] <- "3"
  x$Embarked_Numeric <- as.integer(x$Embarked_Numeric)
  
  # Convertim la variable dependent Survived a factor.
  if("Survived" %in% colnames(x)) {
    x$Survived <- as.character(x$Survived)
    x$Survived[x$Survived=="0"] <- "Died"
    x$Survived[x$Survived=="1"] <- "Survived"
    x$Survived <- as.factor(x$Survived)
  } else {
    
  }
  return(x)
}

# Subconjunt d'entrenament.
titanic_train_clean <- clean_transform(r_train)
head(titanic_train_clean[, c("Survived", "Age", "Fare", "Sex_Numeric", "Pclass", "Embarked_Numeric")])

# Subconjunt de prova.
titanic_test_clean <- clean_transform(r_test)
head(titanic_test_clean[, c("Age", "Fare", "Sex_Numeric", "Pclass", "Embarked_Numeric")])
```

## 3.2. Valors extrems o *outliers*

El següent pas a dur a terme en la fase de la neteja de dades és la identificació i el posterior tractament de valors extrems o *outliers*. Per tal d'identificar aquests valors i veure una representació gràfica de la proporció de registres que representen i com es distribueixen, es realitzaran diagrames de caixes o *boxplots* per les variables numèriques que cal analitzar: `Age`, `SibSp`, `Parch` i `Fare`.
          
```{r boxplots}
# Boxplot per la variable Age.
boxplot(titanic_train_clean$Age,
        main="Distribució variable Age")

# Boxplot per SibSp i Parch.
boxplot(titanic_train_clean[c("SibSp", "Parch")],
        main="Distribució variable Siblings/Spouse i Parch")

# Boxplot per Fare.
boxplot(titanic_train_clean$Fare,
        main="Distribució variable Fare")
```

Als gràfics obtinguts es pot observar el següent:

\begin{enumerate}
  \item Les dues primeres representacions, tot i mostrar punts que es podrien considerar valors extrems, mostren valors raonables d'acord amb la magnitud o realitat que representen. Per aquest motiu, no se'ls descartarà ni es tractaran de cap manera.
  \item L'última figura, corresponent a la variable `Fare`, mostra dos grups considerablement allunyats de la caixa representada. Es considera que aquests punts podrien contenir algun tipus d'error i es decideix reassignar el seu valor pel de la mediana de la variable.
\end{enumerate}

```{r outliers Fare}
titanic_train_clean$Fare[titanic_train_clean$Fare > 200] <-
  median(titanic_train_clean$Fare, na.rm = TRUE)

# Boxplot per Fare.
boxplot(titanic_train_clean$Fare,
        main="Distribució variable Fare")
```

# 4. Anàlisi de les dades

## 4.1. Planificació dels anàlisis

## 4.2. Comprovació de la normalitat i l'homoscedasticitat

Per a fer l'estudi de la normalitat, analitzarem les variables que finalment hem seleccionat per construir el nostre model. Farem l'estudi comprovant si aquelles variables contínues que es troben en els conjunts de dades de train i test presenten una distribució normal o no. Les variables contínues que té sentit que analitzem des d'un punt de vista de distribució normal són: Age i Fare

En primer lloc, farem la representació des d'un punt de vista visual a partir d'histogrames amb les línies de denisitat corresponents.

```{r}
hist(titanic_train_clean$Age, freq = F, ylim = c(0, 0.08), border = "gray50", xlab = "Variable Age", main = "Distribució variable Age (Conjunt Train)")
lines(density(titanic_train_clean$Age))
curve(dnorm(x, mean(titanic_train_clean$Age), sd(titanic_train_clean$Age)), col = "blue", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "blue"), bty = "n", cex = 0.8)
```

```{r}
hist(titanic_train_clean$Age, freq = F, ylim = c(0, 0.06), border = "gray50", xlab = "Variable Fare", main = "Distribució variable Fare (Conjunt Train)")
lines(density(titanic_train_clean$Fare))
curve(dnorm(x, mean(titanic_train_clean$Fare), sd(titanic_train_clean$Fare)), col = "blue", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "blue"), bty = "n", cex = 0.8)
```


Repetim els gràfics per les variables del conjunt de test.



```{r}
hist(titanic_test_clean$Age, freq = F, ylim = c(0, 0.08), border = "gray50", xlab = "Variable Age", main = "Distribució variable Age (Conjunt Test)")
lines(density(titanic_test_clean$Age))
curve(dnorm(x, mean(titanic_test_clean$Age), sd(titanic_test_clean$Age)), col = "red", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "red"), bty = "n", cex = 0.8)
```


```{r}
hist(titanic_test_clean$Fare, freq = F, ylim = c(0, 0.04), border = "gray50", xlab = "Variable Fare", main = "Distribució variable Fare (Conjunt Test)")
lines(density(titanic_test_clean$Fare))
curve(dnorm(x, mean(titanic_test_clean$Fare), sd(titanic_test_clean$Fare)), col = "red", add = T)
legend("topright", c("curva observada", "curva teòrica"),
       lty = 1, lwd = 2, col = c("black", "red"), bty = "n", cex = 0.8)
```

Un cop fetes les representacions gràfiques, tocarà fer-ho des d'un punt de vista estadístic i no tant visual.

Per fer-ho des d'un punt de vista estadístic, realitzarem dos tests: aplicarem el test de Shapiro i el test de Lillie. Per ambdues proves prendrem un nivell de confiança del 95%, essent el nostre valor alfa de 0.05. Així doncs, si el p-valor és inferior a 0.05, no podrem garantir ni assegurar que les nostres variables segueixin una distribució normal. Per altra banda, si el p-valor és superior a 0.05, afirmarem que segueixen una distribució normal.

```{r}
# Apliquem Shapiro Test a les variables del conjunt de train
shapiro.test(titanic_train_clean$Age)
shapiro.test(titanic_train_clean$Fare)

# Apliquem Shapiro Test a les variables del conjunt de test
shapiro.test(titanic_test_clean$Age)
shapiro.test(titanic_test_clean$Fare)
```

Segons el test de Shapiro, cap de les dues variables segueixen una distribució normal, ni pel conjunt d'entrenament ni pel de prova. Tots els p-values estan per sota del nivell de significació del 0.05.

```{r}
# Apliquem Lillie Test a les variables del conjunt de train
lillie.test(titanic_train_clean$Age)
lillie.test(titanic_train_clean$Fare)

# Apliquem Lillie Test a les variables del conjunt de test
lillie.test(titanic_test_clean$Age)
lillie.test(titanic_test_clean$Fare)
```

Si ho verifiquem amb el Lillie test, veiem que segons aquest les dades tampoc segueixen una distribució normal ni pel conjunt de train ni pel de test. Tots els p-values estan per sota del nivell de significació del 0.05.


NOTA: FALTA REALITZAR EL TEST DE LES VARIÀNCIES QUE HO FAREM AMB ANOVA.

## Aplicació dels anàlisis de dades

### Matriu de correlació

```{r correlation matrix}
titanic_train_clean$Sex_Numeric <- titanic_train_clean$Sex_Numeric
titanic_train_clean$Embarked_Numeric <- titanic_train_clean$Embarked_Numeric
corr <-cor(titanic_train_clean[,c("Age", "Fare", "Sex_Numeric", "Pclass",
                                  "SibSp", "Parch")], method = c("pearson"))
corrplot(corr, method="circle")
```

Un cop vista la corrrelació entre les variables que disposem en el nostre dataset, decidim en passar Age, Fare, Sex_Numeric, Embarked_Numeric i Pclass. Certament, veiem que les variables Fare i Pclass estan correlacionades i podríem decidir només passar-ne una. Tot i això, en aquest cas no ens suposa un problema d'alt cost computacional passar totes les variables, i per tant no necessitem fer una reducció de dimensionalitat.

### Arbre de decisió

```{r}
tree <- rpart(Survived ~., data = titanic_train_clean[,c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric", "Pclass")])
rpart.plot(tree)

train_prediction <- predict(tree, titanic_train_clean[,c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric", "Pclass")], type = 'class')
```

```{r}
confMat_train <- table(titanic_train_clean$Survived, train_prediction)
accuracy_tree <- sum(diag(confMat_train))/sum(confMat_train)
cat("El model d'arbre de decisió té una precisió del", round(accuracy_tree*100, 2),"% pel conjunt d'entrenament")
```

```{r}
test_prediction <- predict(tree, titanic_test_clean[,c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric", "Pclass")], type = 'class')
titanic_test_clean$Survived <- test_prediction
head(titanic_test_clean[, c("Survived", "Age", "Fare", "Sex_Numeric", "Embarked_Numeric")], 8)
```

Addicionalment, es presenta a continuació la corba ROC (*Receiver Operating Characteristic*), la qual presenta una primera idea gràfica de la capacitat de discriminació del model: mentre més s'aproxima a la cantonada superior esquerra més discriminant és, mentre que el cas contrari seria que el gràfic presentés una corba totalment plana prop de la diagonal. A més a més, es calcularà també l'àrea sota la corba AUROC (*Area Under the ROC*).

```{r roc tree}
# Canvi de format de la predicció.
train_prediction <- ifelse(train_prediction == "Died",
                           0,
                           1)

# Construcció de la corba ROC.
roc <- roc(titanic_train_clean$Survived,
           train_prediction,
           data = titanic_train_clean)

# Corba ROC.
plot(roc)

# AUROC.
roc
```


### Model de regressió logística

Finalment, es construirà un model de regressió logística amb la finalitat de predir si els passatgers van sobreviure o no en funció de les variables de les quals es disposa.

El primer pas a dur a terme en la construcció del model és el de trobar les variables que resultin significatives. A partir del test de Wald, observant els valors obtinguts per l'estadísic de Wald (*z value*) i el seu p-valor associat ($Pr(>|z|)$), serà immediat comprovar si aquest últim és menor al nivell de significació del test (per defecte $\alpha=0.05$). D'aquesta manera, es podrà concloure que es tracta d'una variable significativa per l'ajust.

```{r logreg}
# Construcció del model.
reg_log <- glm(Survived ~ Age + Sex_Numeric + Fare + Pclass + Embarked_Numeric,
               data = titanic_train_clean,
               family = binomial(link = logit))

summary(reg_log)

# Odds ratio.
exp(coefficients(reg_log))
```

Com es pot observar, l'única variable que pel test de Wald ha resultat no ser significativa ha estat `Fare`, presentant un *p-value* de 0.85. Per tant, aquesta variable no serà considerada alhora de construir el model amb el qual es duran a terme les prediccions sobre el test de prova. Addicionalment, els *odds ratio* o OR calculats per cadascuna de les variables mostren aquelles que són de protecció (OR<1) i aquelles que són variables de risc (OR>1).

Un cop construït el model final de regressió logística s'efectuarà la predicció de la variable Survived pel subconjunt d'entrenament, fet que permetrà avaluar la precisió del model i les seves prediccions.

```{r logreg final}
# Construcció del model FINAL.
reg_log <- glm(Survived ~ Age + Sex_Numeric + Pclass + Embarked_Numeric,
               data = titanic_train_clean,
               family = binomial)

summary(reg_log)

# Odds ratio.
exp(coefficients(reg_log))

# Predicció.
pred_train <- ifelse(predict(reg_log, titanic_train_clean, type = "response")<0.5,
                     0,
                     1)

# Precisió de la predicció.
confMat_train <- table(titanic_train_clean$Survived,
                       pred_train)
accuracy_reg <- sum(diag(confMat_train))/sum(confMat_train)
cat("\nEl model de regressió logística té una precisió del",
    round(accuracy_reg*100, 2),"% pel conjunt d'entrenament.")
```

```{r test prediction}
reg_log_test_prediction <- predict(reg_log,
                           titanic_test_clean[,c("Survived", "Age",
                                                 "Sex_Numeric",
                                                 "Embarked_Numeric","Pclass")],
                           type = 'response')

titanic_test_clean$Survived_Probability <- reg_log_test_prediction

head(titanic_test_clean[, c("Survived_Probability", "Age",
                            "Fare", "Sex_Numeric",
                            "Embarked_Numeric","Pclass")])
```

Veiem que la columna Survived pel conjunt test ens dóna una probabilitat. Podríem dir que els valors superiors a 0.5 són "Survived", mentre que els inferiors a 0.5 els podríem catalogar com a "Died"


Es presenta a continuació la corba ROC pel model de regressió construït. A més a més, es calcula també l'àrea sota la corba AUROC per aquest cas.

```{r glm ROC}
# Construcció de la corba ROC.
roc <- roc(titanic_train_clean$Survived,
           pred_train,
           data = titanic_train_clean)

# Corba ROC.
plot(roc)

# AUROC.
roc
```

La figura mostra que el model és considerablement discriminant, mentre que el valor obtingut per l'AUROC, aproximadament 0.78, permet assgurar que hem acoseguit un model que discrimina de forma adequada i ens trobem molt prop d'un model que discrimina de forma excel·lent, el qual correspon a un AUROC mínim de 0.8.
